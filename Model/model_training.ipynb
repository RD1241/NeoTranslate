{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bea418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 17964\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_lang</th>\n",
       "      <th>target_lang</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>hi</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>en</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>pa</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>en</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>pa</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_lang target_lang                    source_text  \\\n",
       "0          en          hi      We eat tea in the school.   \n",
       "1          hi          en     हम स्कूल में चाय पीते हैं.   \n",
       "2          en          pa      We eat tea in the school.   \n",
       "3          pa          en  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4          hi          pa     हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                     target_text  \n",
       "0     हम स्कूल में चाय पीते हैं.  \n",
       "1      We eat tea in the school.  \n",
       "2  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।  \n",
       "3      We eat tea in the school.  \n",
       "4  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../Data/translator_dataset.csv\")\n",
    "\n",
    "print(\"Total rows:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82799ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_lang</th>\n",
       "      <th>target_lang</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>encoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>hi</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;en&gt; We eat tea in the school.</td>\n",
       "      <td>&lt;start&gt; हम स्कूल में चाय पीते हैं. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>en</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>&lt;hi&gt; हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;start&gt; We eat tea in the school. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>pa</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;en&gt; We eat tea in the school.</td>\n",
       "      <td>&lt;start&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>en</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>&lt;pa&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;start&gt; We eat tea in the school. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>pa</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;hi&gt; हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;start&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_lang target_lang                    source_text  \\\n",
       "0          en          hi      We eat tea in the school.   \n",
       "1          hi          en     हम स्कूल में चाय पीते हैं.   \n",
       "2          en          pa      We eat tea in the school.   \n",
       "3          pa          en  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4          hi          pa     हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                     target_text                       encoder_input  \\\n",
       "0     हम स्कूल में चाय पीते हैं.      <en> We eat tea in the school.   \n",
       "1      We eat tea in the school.     <hi> हम स्कूल में चाय पीते हैं.   \n",
       "2  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।      <en> We eat tea in the school.   \n",
       "3      We eat tea in the school.  <pa> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।     <hi> हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                                decoder_target  \n",
       "0     <start> हम स्कूल में चाय पीते हैं. <end>  \n",
       "1      <start> We eat tea in the school. <end>  \n",
       "2  <start> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। <end>  \n",
       "3      <start> We eat tea in the school. <end>  \n",
       "4  <start> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। <end>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_tokens(row):\n",
    "    source = f\"<{row['source_lang']}> {row['source_text']}\"\n",
    "    target = f\"<start> {row['target_text']} <end>\"\n",
    "    return pd.Series([source, target])\n",
    "\n",
    "df[[\"encoder_input\", \"decoder_target\"]] = df.apply(add_tokens, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80b3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Vocabulary size: 411\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "all_text = list(df[\"encoder_input\"]) + list(df[\"decoder_target\"])\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d543e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sequences = tokenizer.texts_to_sequences(df[\"encoder_input\"])\n",
    "decoder_sequences = tokenizer.texts_to_sequences(df[\"decoder_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc439e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder shape: (17964, 10)\n",
      "Decoder shape: (17964, 11)\n"
     ]
    }
   ],
   "source": [
    "max_encoder_len = max(len(seq) for seq in encoder_sequences)\n",
    "max_decoder_len = max(len(seq) for seq in decoder_sequences)\n",
    "\n",
    "encoder_padded = pad_sequences(encoder_sequences, maxlen=max_encoder_len, padding='post')\n",
    "decoder_padded = pad_sequences(decoder_sequences, maxlen=max_decoder_len, padding='post')\n",
    "\n",
    "print(\"Encoder shape:\", encoder_padded.shape)\n",
    "print(\"Decoder shape:\", decoder_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15e9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input shape: (17964, 10)\n",
      "Decoder output shape: (17964, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "decoder_input = decoder_padded[:, :-1]\n",
    "decoder_output = decoder_padded[:, 1:]\n",
    "\n",
    "print(\"Decoder input shape:\", decoder_input.shape)\n",
    "print(\"Decoder output shape:\", decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1417fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 10, 128)              52608     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 10, 128)              52608     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                394240    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 10, 256),            394240    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 10, 411)              105627    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 999323 (3.81 MB)\n",
      "Trainable params: 999323 (3.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "embedding_dim = 128\n",
    "latent_dim = 256\n",
    "\n",
    "# ----- ENCODER -----\n",
    "encoder_inputs = Input(shape=(max_encoder_len,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# ----- DECODER -----\n",
    "decoder_inputs = Input(shape=(max_decoder_len - 1,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# ----- FULL MODEL -----\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5ad961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5878442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = np.expand_dims(decoder_output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "339df8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "253/253 [==============================] - 10s 31ms/step - loss: 2.1902 - accuracy: 0.5099 - val_loss: 1.3372 - val_accuracy: 0.6013\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 1.1926 - accuracy: 0.6261 - val_loss: 1.1609 - val_accuracy: 0.6325\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 1.0500 - accuracy: 0.6568 - val_loss: 0.9852 - val_accuracy: 0.6711\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.8723 - accuracy: 0.6987 - val_loss: 0.8579 - val_accuracy: 0.7073\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.7526 - accuracy: 0.7362 - val_loss: 0.7386 - val_accuracy: 0.7426\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.6302 - accuracy: 0.7737 - val_loss: 0.6157 - val_accuracy: 0.7801\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.4951 - accuracy: 0.8131 - val_loss: 0.4733 - val_accuracy: 0.8301\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.3556 - accuracy: 0.8683 - val_loss: 0.3442 - val_accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.2481 - accuracy: 0.9062 - val_loss: 0.2670 - val_accuracy: 0.9009\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 6s 25ms/step - loss: 0.1925 - accuracy: 0.9192 - val_loss: 0.2274 - val_accuracy: 0.9119\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.1634 - accuracy: 0.9253 - val_loss: 0.2111 - val_accuracy: 0.9156\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.1473 - accuracy: 0.9278 - val_loss: 0.2005 - val_accuracy: 0.9176\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.1386 - accuracy: 0.9291 - val_loss: 0.1987 - val_accuracy: 0.9183\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.1339 - accuracy: 0.9303 - val_loss: 0.1952 - val_accuracy: 0.9179\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 6s 25ms/step - loss: 0.1252 - accuracy: 0.9327 - val_loss: 0.1911 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.1199 - accuracy: 0.9338 - val_loss: 0.1961 - val_accuracy: 0.9180\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.1171 - accuracy: 0.9352 - val_loss: 0.1894 - val_accuracy: 0.9206\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 7s 27ms/step - loss: 0.1131 - accuracy: 0.9350 - val_loss: 0.1906 - val_accuracy: 0.9196\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 6s 25ms/step - loss: 0.1103 - accuracy: 0.9367 - val_loss: 0.1921 - val_accuracy: 0.9198\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 7s 26ms/step - loss: 0.1086 - accuracy: 0.9378 - val_loss: 0.1900 - val_accuracy: 0.9196\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [encoder_padded, decoder_input],\n",
    "    decoder_output,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77aad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model for inference\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bdb70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder setup\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding2 = decoder_embedding\n",
    "decoder_lstm_outputs, state_h2, state_c2 = decoder_lstm(\n",
    "    decoder_embedding2,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_states = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf06e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {v: k for k, v in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c88f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(source_lang, sentence):\n",
    "    \n",
    "    # Format input exactly like training\n",
    "    input_text = f\"<{source_lang}> {sentence}\"\n",
    "    \n",
    "    # Convert to sequence\n",
    "    sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    sequence = pad_sequences(sequence, maxlen=max_encoder_len, padding='post')\n",
    "\n",
    "    # Get encoder states\n",
    "    states_value = encoder_model.predict(sequence, verbose=0)\n",
    "\n",
    "    # Start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[\"<start>\"]\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    for _ in range(max_decoder_len):\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_word_index.get(sampled_token_index, \"\")\n",
    "\n",
    "        if sampled_word == \"<end>\" or sampled_word == \"\":\n",
    "            break\n",
    "\n",
    "        decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        # Update target sequence\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "036d5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।\n",
      "we eat tea in the school.\n",
      "हम स्कूल में चाय पीते हैं.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"en\", \"We eat tea in the school.\"))\n",
    "print(translate_sentence(\"hi\", \"हम स्कूल में चाय पीते हैं.\"))\n",
    "print(translate_sentence(\"pa\", \"ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4a018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"translator_training_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac2b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save(\"encoder_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3a1939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "decoder_model.save(\"decoder_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acf54490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b9e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.133.1-py3-none-any.whl (109 kB)\n",
      "     ---------------------------------------- 0.0/109.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/109.0 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/109.0 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 30.7/109.0 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/109.0 kB 393.8 kB/s eta 0:00:01\n",
      "     ------------------------------- ----- 92.2/109.0 kB 585.1 kB/s eta 0:00:01\n",
      "     ------------------------------- ----- 92.2/109.0 kB 585.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 109.0/109.0 kB 486.6 kB/s eta 0:00:00\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.41.0-py3-none-any.whl (68 kB)\n",
      "     ---------------------------------------- 0.0/68.8 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 41.0/68.8 kB 991.0 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 61.4/68.8 kB 812.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 68.8/68.8 kB 537.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (3.1.3)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.22-py3-none-any.whl (24 kB)\n",
      "Collecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from fastapi) (0.0.4)\n",
      "Collecting starlette>=0.40.0\n",
      "  Downloading starlette-0.52.1-py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 0.0/74.3 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 41.0/74.3 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------------- ----------------- 41.0/74.3 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 74.3/74.3 kB 587.4 kB/s eta 0:00:00\n",
      "Collecting pydantic>=2.7.0\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "     ---------------------------------------- 0.0/463.6 kB ? eta -:--:--\n",
      "     --- ----------------------------------- 41.0/463.6 kB 2.0 MB/s eta 0:00:01\n",
      "     --- ----------------------------------- 41.0/463.6 kB 2.0 MB/s eta 0:00:01\n",
      "     ------- ----------------------------- 92.2/463.6 kB 655.4 kB/s eta 0:00:01\n",
      "     -------------- ----------------------- 174.1/463.6 kB 1.2 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 225.3/463.6 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 256.0/463.6 kB 1.1 MB/s eta 0:00:01\n",
      "     --------------------- -------------- 276.5/463.6 kB 899.5 kB/s eta 0:00:01\n",
      "     ------------------------------ ------- 368.6/463.6 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 368.6/463.6 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ---- 399.4/463.6 kB 958.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 463.6/463.6 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from jinja2) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/2.0 MB 4.1 MB/s eta 0:00:01\n",
      "     - -------------------------------------- 0.1/2.0 MB 4.1 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 0.2/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/2.0 MB 1.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.3/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/2.0 MB 1.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/2.0 MB 1.4 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.5/2.0 MB 1.4 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.5/2.0 MB 1.4 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.5/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.6/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.6/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 0.7/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 0.7/2.0 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.8/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.8/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.9/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.0/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.0/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.4/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.4/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.4/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.5/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.5/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.7/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.7/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.9/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from starlette>=0.40.0->fastapi) (4.12.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from anyio<5,>=3.6.2->starlette>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\documents\\ibm_sem4\\generative_ai_ca\\genai_env310\\lib\\site-packages (from anyio<5,>=3.6.2->starlette>=0.40.0->fastapi) (3.11)\n",
      "Installing collected packages: typing-inspection, python-multipart, pydantic-core, annotated-types, uvicorn, pydantic, starlette, fastapi\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.133.1 pydantic-2.12.5 pydantic-core-2.41.5 python-multipart-0.0.22 starlette-0.52.1 typing-inspection-0.4.2 uvicorn-0.41.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn jinja2 python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd01915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (genai_env310)",
   "language": "python",
   "name": "genai_env310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
