{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b70e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_lang</th>\n",
       "      <th>target_lang</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>hi</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>en</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>pa</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>en</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>pa</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_lang target_lang                    source_text  \\\n",
       "0          en          hi      We eat tea in the school.   \n",
       "1          hi          en     हम स्कूल में चाय पीते हैं.   \n",
       "2          en          pa      We eat tea in the school.   \n",
       "3          pa          en  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4          hi          pa     हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                     target_text  \n",
       "0     हम स्कूल में चाय पीते हैं.  \n",
       "1      We eat tea in the school.  \n",
       "2  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।  \n",
       "3      We eat tea in the school.  \n",
       "4  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../Data/translator_dataset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538f49df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_lang</th>\n",
       "      <th>target_lang</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>encoder_input</th>\n",
       "      <th>decoder_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>hi</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;en&gt; &lt;to_hi&gt; We eat tea in the school.</td>\n",
       "      <td>&lt;start&gt; हम स्कूल में चाय पीते हैं. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>en</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>&lt;hi&gt; &lt;to_en&gt; हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;start&gt; We eat tea in the school. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>pa</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;en&gt; &lt;to_pa&gt; We eat tea in the school.</td>\n",
       "      <td>&lt;start&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>en</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>We eat tea in the school.</td>\n",
       "      <td>&lt;pa&gt; &lt;to_en&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;start&gt; We eat tea in the school. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>pa</td>\n",
       "      <td>हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।</td>\n",
       "      <td>&lt;hi&gt; &lt;to_pa&gt; हम स्कूल में चाय पीते हैं.</td>\n",
       "      <td>&lt;start&gt; ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_lang target_lang                    source_text  \\\n",
       "0          en          hi      We eat tea in the school.   \n",
       "1          hi          en     हम स्कूल में चाय पीते हैं.   \n",
       "2          en          pa      We eat tea in the school.   \n",
       "3          pa          en  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4          hi          pa     हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                     target_text                               encoder_input  \\\n",
       "0     हम स्कूल में चाय पीते हैं.      <en> <to_hi> We eat tea in the school.   \n",
       "1      We eat tea in the school.     <hi> <to_en> हम स्कूल में चाय पीते हैं.   \n",
       "2  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।      <en> <to_pa> We eat tea in the school.   \n",
       "3      We eat tea in the school.  <pa> <to_en> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।   \n",
       "4  ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ।     <hi> <to_pa> हम स्कूल में चाय पीते हैं.   \n",
       "\n",
       "                                decoder_output  \n",
       "0     <start> हम स्कूल में चाय पीते हैं. <end>  \n",
       "1      <start> We eat tea in the school. <end>  \n",
       "2  <start> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। <end>  \n",
       "3      <start> We eat tea in the school. <end>  \n",
       "4  <start> ਅਸੀਂ ਸਕੂਲ ਵਿੱਚ ਚਾਹ ਖਾਂਦੇ ਹਾਂ। <end>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_tokens(row):\n",
    "    source_lang = row[\"source_lang\"]\n",
    "    target_lang = row[\"target_lang\"]\n",
    "    \n",
    "    source = f\"<{source_lang}> <to_{target_lang}> {row['source_text']}\"\n",
    "    target = f\"<start> {row['target_text']} <end>\"\n",
    "    \n",
    "    return pd.Series([source, target])\n",
    "\n",
    "df[[\"encoder_input\", \"decoder_output\"]] = df.apply(add_tokens, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_len = 20\n",
    "max_decoder_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d08f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Vocabulary size: 414\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "all_text = list(df[\"encoder_input\"]) + list(df[\"decoder_output\"])\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413dcb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sequences = tokenizer.texts_to_sequences(df[\"encoder_input\"])\n",
    "decoder_sequences = tokenizer.texts_to_sequences(df[\"decoder_output\"])\n",
    "\n",
    "encoder_input_data = pad_sequences(encoder_sequences, maxlen=max_encoder_len, padding='post')\n",
    "decoder_input_data = pad_sequences(decoder_sequences, maxlen=max_decoder_len, padding='post')\n",
    "\n",
    "decoder_output_data = decoder_input_data[:, 1:]\n",
    "decoder_input_data = decoder_input_data[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4dac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb30c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_encoder_len,))\n",
    "enc_emb = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_decoder_len - 1,))\n",
    "dec_emb_layer = Embedding(vocab_size, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeedb668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 19)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 20, 256)              105984    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 19, 256)              105984    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 512),                1574912   ['embedding[0][0]']           \n",
      "                              (None, 512),                                                        \n",
      "                              (None, 512)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 19, 512),            1574912   ['embedding_1[0][0]',         \n",
      "                              (None, 512),                           'lstm[0][1]',                \n",
      "                              (None, 512)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 19, 414)              212382    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3574174 (13.63 MB)\n",
      "Trainable params: 3574174 (13.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a220b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\dell\\Documents\\IBM_Sem4\\Generative_AI_CA\\genai_env310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "253/253 [==============================] - 34s 127ms/step - loss: 1.0741 - accuracy: 0.7545 - val_loss: 0.6732 - val_accuracy: 0.7950\n",
      "Epoch 2/40\n",
      "253/253 [==============================] - 33s 130ms/step - loss: 0.5833 - accuracy: 0.8105 - val_loss: 0.5693 - val_accuracy: 0.8135\n",
      "Epoch 3/40\n",
      "253/253 [==============================] - 68s 270ms/step - loss: 0.5094 - accuracy: 0.8231 - val_loss: 0.4938 - val_accuracy: 0.8284\n",
      "Epoch 4/40\n",
      "253/253 [==============================] - 40s 155ms/step - loss: 0.4515 - accuracy: 0.8377 - val_loss: 0.4499 - val_accuracy: 0.8415\n",
      "Epoch 5/40\n",
      "253/253 [==============================] - 42s 167ms/step - loss: 0.4042 - accuracy: 0.8517 - val_loss: 0.4043 - val_accuracy: 0.8552\n",
      "Epoch 6/40\n",
      "253/253 [==============================] - 54s 214ms/step - loss: 0.3509 - accuracy: 0.8680 - val_loss: 0.3535 - val_accuracy: 0.8754\n",
      "Epoch 7/40\n",
      "253/253 [==============================] - 77s 303ms/step - loss: 0.3000 - accuracy: 0.8867 - val_loss: 0.3096 - val_accuracy: 0.8878\n",
      "Epoch 8/40\n",
      "253/253 [==============================] - 101s 399ms/step - loss: 0.2616 - accuracy: 0.9011 - val_loss: 0.2861 - val_accuracy: 0.8968\n",
      "Epoch 9/40\n",
      "253/253 [==============================] - 103s 409ms/step - loss: 0.2288 - accuracy: 0.9133 - val_loss: 0.2597 - val_accuracy: 0.9082\n",
      "Epoch 10/40\n",
      "253/253 [==============================] - 77s 303ms/step - loss: 0.2086 - accuracy: 0.9217 - val_loss: 0.2422 - val_accuracy: 0.9167\n",
      "Epoch 11/40\n",
      "253/253 [==============================] - 51s 202ms/step - loss: 0.1911 - accuracy: 0.9298 - val_loss: 0.2447 - val_accuracy: 0.9170\n",
      "Epoch 12/40\n",
      "253/253 [==============================] - 41s 163ms/step - loss: 0.1755 - accuracy: 0.9359 - val_loss: 0.2167 - val_accuracy: 0.9277\n",
      "Epoch 13/40\n",
      "253/253 [==============================] - 37s 146ms/step - loss: 0.1580 - accuracy: 0.9415 - val_loss: 0.2014 - val_accuracy: 0.9296\n",
      "Epoch 14/40\n",
      "253/253 [==============================] - 31s 122ms/step - loss: 0.1321 - accuracy: 0.9500 - val_loss: 0.1635 - val_accuracy: 0.9439\n",
      "Epoch 15/40\n",
      "253/253 [==============================] - 31s 124ms/step - loss: 0.0900 - accuracy: 0.9669 - val_loss: 0.1166 - val_accuracy: 0.9644\n",
      "Epoch 16/40\n",
      "253/253 [==============================] - 32s 125ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.1025 - val_accuracy: 0.9731\n",
      "Epoch 17/40\n",
      "253/253 [==============================] - 31s 123ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.0824 - val_accuracy: 0.9774\n",
      "Epoch 18/40\n",
      "253/253 [==============================] - 33s 132ms/step - loss: 0.0276 - accuracy: 0.9899 - val_loss: 0.0785 - val_accuracy: 0.9793\n",
      "Epoch 19/40\n",
      "253/253 [==============================] - 31s 124ms/step - loss: 0.0261 - accuracy: 0.9904 - val_loss: 0.0764 - val_accuracy: 0.9802\n",
      "Epoch 20/40\n",
      "253/253 [==============================] - 31s 122ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.0732 - val_accuracy: 0.9811\n",
      "Epoch 21/40\n",
      "253/253 [==============================] - 31s 124ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.0758 - val_accuracy: 0.9800\n",
      "Epoch 22/40\n",
      "253/253 [==============================] - 31s 123ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0838 - val_accuracy: 0.9786\n",
      "Epoch 23/40\n",
      "253/253 [==============================] - 31s 124ms/step - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.0780 - val_accuracy: 0.9803\n",
      "Epoch 24/40\n",
      "253/253 [==============================] - 31s 123ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0778 - val_accuracy: 0.9805\n",
      "Epoch 25/40\n",
      "253/253 [==============================] - 31s 123ms/step - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.0783 - val_accuracy: 0.9806\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_output_data,\n",
    "    batch_size=64,\n",
    "    epochs=40,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bdf9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0785187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# State inputs\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Reuse embedding layer\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Run LSTM with new state inputs\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
    "    dec_emb2,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e89b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"full_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8adb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save(\"encoder_model_v2.h5\")\n",
    "decoder_model.save(\"decoder_model_v2.h5\")\n",
    "\n",
    "import pickle\n",
    "with open(\"tokenizer_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202a962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (genai_env310)",
   "language": "python",
   "name": "genai_env310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
